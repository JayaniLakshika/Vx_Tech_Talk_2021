<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Computer Vision System for Automated Medicinal Plant Identification</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jayani Lakshika" />
    <meta name="date" content="2021-09-30" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-style.css" type="text/css" />
    <link rel="stylesheet" href="animate.css" type="text/css" />
    <link rel="stylesheet" href="dt.css" type="text/css" />
    <link rel="stylesheet" href="col.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Computer Vision System for Automated Medicinal Plant Identification
## TECH TALK
### Jayani Lakshika
### Associate Data Analyst
### September 30, 2021

---





class: center, middle

## My SUPERVISOR

&lt;img src="madam.jpg" width="30%" style="display: block; margin: auto;" /&gt;

Dr. Thiyanga S. Talagala

Senior Lecturer in the Department of Statistics, Faculty of Applied Sciences at the University of Sri Jayewardenepura

PhD in Statistics, Monash University, Australia

https://thiyanga.netlify.app/

---
class: center, middle

&lt;img src="jj.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="vx.jfif" width="30%" style="display: block; margin: auto;" /&gt;

---
background-image: url("bg1.png")
background-size: 900px
background-position: 90% 8%


---
## Main objective

- **.red[To develop an automatic algorithm to classify medicinal plants by using statistical machine learning approach]**

&lt;img src="pp.png" width="30%" style="display: block; margin: auto;" /&gt;

---
# Limitations

**Why medicinal plant leaves?**

--
- Leaf images are considered as they contain large number of diverse set of features such as **.orange[shape, veins, edge features, apices, etc]**. 

&lt;img src="simple_leaf_parts.png" style="width: 40%" /&gt;&lt;img src="full.png" style="width: 40%" /&gt;

--
- We used **.red[non-diseased leaves with simple arrangement]**.

--
- We used the leaves **.red[without a petiole.]** 

---
# Significance of the study

- **.red[To avoid misidentifying medicinal plants in Sri Lanka]**

- The algorithm developed by us is based on the leaf images. Since leaves are **.red[relatively easy to obtain without damaging the plants]**, there is no harm for the plants because of the development of algorithm. 

- Our algorithm works as a hierarchical classification system. Therefore even though we don't know the exact species name, we can follow the first 2 levels. As the result of that **.red[misidentification rate and computation time will be decreased]**.

&lt;img src="diagram.png" width="60%" style="display: block; margin: auto;" /&gt;

---
class: inverse, center, middle

# Methodology
![](leafim.png)


---
## Workflow

&lt;img src="algo_new.png" width="50%" style="display: block; margin: auto;" /&gt;



---
## Image Acquisition


- A database of leaf images of medicinal plants in Sri Lanka **.orange[is not yet available]**. 

- **.green[Establish a repository of medicinal plant images]**. 

- Preliminary study by using **.red[471 medicinal plants]** and recorded their characteristics like **.purple[leaf arrangement, shape, edge type etc]**.

&lt;img src="pic.png" style="width: 80%" /&gt;

---
- Collected **.red[1099]** leaf images from **.red[31 species]**
&lt;img src="actual_image_collection_process.png" style="width: 100%" /&gt;


**MedLEA: Medicinal LEAf**

&lt;img src="MedLEA.png" width="55%" style="display: block; margin: auto;" /&gt;

repository is made available to the public through an **.red[open-source R software MedLEA]**, available at url(https://CRAN.R-project.org/package=MedLEA) for research reproducibility

**.red[Total downloads: More than 1000]**
---
&lt;img src="ima.png" style="width: 100%" /&gt;

&lt;img src="datasets.png" style="width: 60%" /&gt;

---
## Methodology Diagram

&lt;img src="ov.png" width="110%" height="110%" style="display: block; margin: auto;" /&gt;


---
# Image processing

- The image processing receives an image as input and generates a **.green[modified image]** as an output which is suitable for better **.orange[morphological analysis, feature extraction]**. 

- Image processing is an essential step to **.red[reduce noise, background subtraction and content enhancement]** in the identification process. 

&lt;img src="image_processing.png" style="width: 100%" /&gt;
--
&lt;img src="close_holes.png" style="width: 30%" /&gt; &lt;img src="remove_stalk.png" style="width: 30%" /&gt;

---
## Methodology Diagram

&lt;img src="ov.png" width="110%" height="110%" style="display: block; margin: auto;" /&gt;


---

# Why feature extraction is important?

- Recently, many researchers use deep learning methods like CNN (Convolution Neural Network) to classify plants - directly using plant images. 

- Even though deep learning models have achieved great success, their interpretability, and transparency of the deep learning models are limited.

&lt;img src="CNN.png" width="110%" height="110%" style="display: block; margin: auto;" /&gt;
---

# Features

- In identification of plant species by using leaf images, **.green[features of the leaves play a main role]**.

--

- In previous research, let the algorithm like **.red[CNN]** to extract features by itself and do the classification. 

--

- Therefore it is so **.purple[hard to interpret and generalize]** the features. 

--

- We introduced **.red[pre-calculate features]** which can be **.green[easy to interpret and generalize]**. They are also **.green[computational efficient]**. 

--
&lt;img src="feature_hie.png" width="80%" style="display: block; margin: auto;" /&gt;

- We identified altogether **.orange[52 features]**.

---
### Shape features
&lt;img src="shape.png" width="80%" style="display: block; margin: auto;" /&gt;

**New shape features: Correlation of cartesian coordinate, number of convex points, number of minimum and maximum points**

&lt;img src="mn.png" width="45%" style="display: block; margin: auto;" /&gt;
---
class: center, middle

**Diameter calculation**

&lt;img src="d_cal.png" style="width: 68%" /&gt;

---
### Color features

&lt;img src="leaf_img.png" width="50%" style="display: block; margin: auto;" /&gt;

&lt;img src="col_eq.png" width="60%" style="display: block; margin: auto;" /&gt;

---
### Texture features

&lt;img src="text_tb.png" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="t1.png" width="50%" style="display: block; margin: auto;" /&gt;

&lt;img src="t2.png" width="50%" style="display: block; margin: auto;" /&gt;

---
### Scagnostic features

&lt;img src="scp.png" width="70%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="sca.png" width="60%" style="display: block; margin: auto;" /&gt;

---
## Visualization of Leaf Images in the Feature Space
Example: Flavia

- LDA is a supervised dimensionality reduction technique, and PCA is unsupervised dimensionality reduction technique

- The first **.green[three principal components (PCs)]** accounting for approximately **.red[83%]** of the total variance in the original data

&lt;img src="pcaflavia.png" width="70%" style="display: block; margin: auto;" /&gt;

---
class: inverse, center, middle

# Let's see the 3D View
---

&lt;img src="ldaflavia.png" width="100%" style="display: block; margin: auto;" /&gt;

- Under both experimental settings class separation is **.orange[more clearly on the LDA space than the PCA space]**. The reason could be LDA is a supervised learning algorithm while PCA space is an unsupervised learning algorithm.

---
![](Overview_new1.png)


---
class: inverse, center, middle

# Algorithm Development
![](leafim.png)


---


- Our medicinal plant classification algorithm contains **.green[two process: Training process and Test process]**.

- Our classification algorithm operates on the **.purple[features extracted from the image leaves]**. 

- The training process e of the algorithm contains four main steps: **.orange[i) Image processing, ii) Feature extraction, iii) Label images, and iv) Trained a algorithm]**.

- In the test process, image processing and feature extraction steps are followed by the **.orange[new image before feed to the pre-trained model]**. 

- Mainly **.red[Random Forest, Gradient Boosting and Extreme Gradient Boosting]** classification algorithms are used in our research.

&lt;img src="algo.png" width="70%" style="display: block; margin: auto;" /&gt;

---
### MEDIPI: MEDIcinal Plant Identification 

&lt;img src="sticker1.png" width="20%" style="display: block; margin: auto;" /&gt;

Our medicinal plant classification algorithm is defined as **.red[MEDIPI]**. 

&lt;img src="algo_new_1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
class: inverse, center, middle

# Discussion &amp; Conclusions
![](leafim.png)

---
# Hierarchical Approach

- Our algorithm works as a **.red[hierarchical classification system]**. The hierarchy contains **.purple[3 levels]**. The first level classifies images according to the **.red[shape]**. The second level classifies according to the **.red[edge types]**. The bottom level classifies the **.red[plant species]**.

&lt;img src="diagram.png" style="width: 90%" /&gt;


---
## Hierarchy of Actual leaf image dataset
&lt;img src="Classification_hierarchy_new.png" style="width: 90%" /&gt;

---
## Hierarchy of Flavia leaf image dataset

&lt;img src="hie.png" style="width: 90%" /&gt;
---
class: center, middle

### Experiments

&lt;img src="exp.png" style="width: 100%" /&gt;

We have to use **.orange[training/test from same dataset]** to get accurate results.

---
## Compare results features of all categories and only with shape features
Training and test datasets from same dataset

&lt;img src="comp1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
## Compare results features of all categories and only with shape features
Training and test datasets from different datasets

&lt;img src="comp2.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# Compare algorithms

&lt;img src="tb11.png" width="80%" style="display: block; margin: auto;" /&gt;

The model trained with **.red[Random Forest]** algorithm provides the highest accuracy.


---

## Linear Discriminant Analysis

- High dimensional visualization approach  

- To visualize what is **.red[happening inside]** the trained algorithm and provides **.red[transparency]** to our black-box model


&lt;img src="actp7.png" style="width: 90%" /&gt;

---

&lt;img src="actp10.png" style="width: 110%" /&gt;

---

&lt;img src="actp11.png" style="width: 110%" /&gt;


---
&lt;img src="actp12.png" style="width: 110%" /&gt;

---

&lt;img src="actp13.png" style="width: 110%" /&gt;

---
&lt;img src="actp14.png" style="width: 110%" /&gt;

---
&lt;img src="actp9.png" style="width: 110%" /&gt;

---
## Conclusions

- The model trained with **.red[random forest]** algorithm provides the highest accuracy.

--

- Our algorithm works as a **.red[hierarchical classification system]**. 

--
- We observe that **.red[shape features]** like (i) x value of Center (cx), (ii) y value of Center (cy), (iii) Entropy, (iv) Perimeter ratio of length and width, (v) Diameter, (vi) Area convexity, (vii) Perimeter convexity, (viii) Narrow Factor, (ix) Area ratio convexity, (x) Physiological length, (xi) Physiological width, (xii) Rectangularity, and (xiii) Eccentricity are more important when classify the leaf images in the **.red[first level]** of the hierarchy. 

- **.red[Scagnostic features]** like (i) Monotonic contour, (ii) Convex polar, (iii) Convex contour, (iv) Striated polar, (v) Striated contour, (vii) Skinny contour, and (vii) Skinny contour are more important in identifying leaf species in the **.red[bottom level]** of the hierarchy.

--
- The **.red[MEDIPI]** algorithm yields accurate results to the state-of-the existing techniques in the field. 

--
- We have to use **.red[training/test from same dataset]** to get accurate results.  

--
- We observe that **.red[shape feature is not sufficient]** to classify leaf images. 


---
class: inverse, center, middle

# Thesis Outcome
![](leafim.png)


---
class: center, middle
## MedLEA

&lt;img src="git_sc.png" width="80%" style="display: block; margin: auto;" /&gt;

https://CRAN.R-project.org/package=MedLEA

---
class: center, middle

background-color: #c2a5cf

## Research paper 
&lt;img src="researchpaper_new.png" width="105%" style="display: block; margin: auto;" /&gt;

https://arxiv.org/abs/2106.08077

---
## Web Application for Leaf Image Identification

&lt;img src="shinyapp.png" width="70%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="octave.jpg" width="80%" style="display: block; margin: auto;" /&gt;

---
background-color: #bdbdbd

# Applied Statistics Conference 2021 (Solvenia)

&lt;img src="Poster.png" width="70%" style="display: block; margin: auto;" /&gt;

https://akastrin.si/as2021/

---
background-color: #bdbdbd

# Young Scientists' Conference on Multidisciplinary Research (YSCMR 2021)
## Organised by the Young Scientists’ Association of the National Institute of Fundamental Studies, Sri Lanka (NIFS-YSA)

&lt;img src="ycmr.png" width="30%" style="display: block; margin: auto;" /&gt;

---
class: center, middle
# Thanks!

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

Slides are available at github: https://github.com/JayaniLakshika/Estadistica_2021

---

class: center, middle

&lt;img src="scr.png" style="width: 100%"/&gt;

 The website "AYURVEDIC MEDICINAL PLANTS OF SRI LANKA" (\url(http://www.instituteofayurveda.org/plants/))


---
# Robust scaling

- If there are input variables that have very large values relative to the other input variables, these large values can dominate or skew some machine learning algorithms (eg: ANN, KNN, SVM etc).

- The result is that algorithm pay more attention to the large values and ignore the variables with smaller values. 


---

![](sca.png)

---
Flavia hierarchy

![](hie.png)

---

## Synthetic Minority Oversampling Technique (SMOTE)

- Imbalance dataset is a classification problem where the class distribution is biased or skewed or not uniform. Most machine learning algorithms for classification are designed under the assumption that each class has an equal number of observations. That results, especially for the minority class in the model, has poor predictive performance. Even though minority class is more important, classification errors for minority class is more sensitive than majority class.

- One remedy for class imbalance is to use an over-sampling method. SMOTE is an over-sampling method which creates synthetic (not duplicates) samples for the minority class and makes the minority class equal to the majority class. By selecting similar records and altering that record one column at a time by random amount within the difference to the neighbouring records, SMOTE handles the imbalance problem.

---
class: inverse, center, middle

# Key Insights
![](leafim.png)

---



- Most of the research are based on existing databases. Even though researchers used their own database most of the time they didn't define image acquisition process in detail or it was complex. Therefore through this research, we introduced simplest and reliable approach of acquiring leaf images which can be followed without expertise knowledge. 

--

- To classify leaf images, several reliable automatic procedures are used. But we introduced a hierarchical approach which perform better than non hierarchical approaches. 

--
- Random Forest in hierarchical approach

--
- We have to use training/test from same dataset to get accurate results.  



---

# Further Research

- Develop algorithms to identify plant disease in Sri Lanka

--
- Expand the species collection

--
- Explore differences in plant features according to spatial distributions and climate conditions (For example, Gotukola leaf in Colombo is smaller than in Anuradhapura)

--
- Develop an algorithm to handle images with heterogeneous backgrounds
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
